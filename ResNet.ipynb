{"cells":[{"cell_type":"markdown","metadata":{"id":"RlZu1rxMt77N"},"source":["# For Training and Loading the Pretrained Model on a Fresh Dataset"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"gkwITU5hFTpM","executionInfo":{"status":"ok","timestamp":1668261124091,"user_tz":-330,"elapsed":2123,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from matplotlib.pyplot import imread\n","from keras.layers import Input\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","# import tf.keras.callbacks "]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1668261124091,"user":{"displayName":"totally reliable","userId":"15953242274047744585"},"user_tz":-330},"id":"ZyAYm1hIJ5AF","outputId":"3695780c-3c00-4a6b-b83e-053732d41665"},"outputs":[{"output_type":"stream","name":"stdout","text":["TF version: 2.9.2\n","Hub version: 0.12.0\n","GPU available\n"]}],"source":["print(\"TF version:\", tf.__version__)\n","print(\"Hub version:\", hub.__version__)\n","\n","# Check for GPU\n","print(\"GPU\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"not available\")"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"9rcTFkleBhQb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668261159676,"user_tz":-330,"elapsed":35596,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"343b77c6-d9b0-488e-e695-f410a44c8cf8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["# # Running this cell will provide you with a token to link your drive to this notebook\n","from google.colab import drive\n","import sys\n","\n","drive.mount('/content/gdrive/')\n","sys.path.append('/content/gdrive/My Drive/Datathon/')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"wYX_zML-Bvwv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668261159677,"user_tz":-330,"elapsed":10,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"ef0381ac-e546-4fd2-de48-4f76c403f289"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/.shortcut-targets-by-id/18Pjuiby86W8tPsgJuQAMo0AMjzsG0pLw/Datathon\n"]}],"source":["%cd '/content/gdrive/My Drive/Datathon/'"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Ay8RDA8iB7lZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668261159677,"user_tz":-330,"elapsed":8,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"f5c3b552-507f-4727-b013-c422e4fcb52c"},"outputs":[{"output_type":"stream","name":"stdout","text":[" Datathon2.ipynb\t\t        models\n"," datathonindoml-2022.zip\t        models_archit\n"," dense-net-logger.csv\t\t       'New Models.ipynb'\n"," drive\t\t\t\t        predicted_label_3.csv\n"," efficient-net-logger.csv\t        predicted_label.csv\n","'for RESNETS.ipynb'\t\t        res-net-logger.csv\n"," kaggle-indoml-submission.csv\t        sample_submission.csv\n"," kaggle-indoml-submission-model-2.csv   train\n"," logs\t\t\t\t        train_labels.csv\n"," mobile-net-logger.csv\t\t        validation\n"," mobile-net-logger.gsheet\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"tO79ce92J6hH","executionInfo":{"status":"ok","timestamp":1668261161494,"user_tz":-330,"elapsed":1822,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["train_labels_csv = pd.read_csv(\"train_labels.csv\")"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"fDXtkZfjKF-H","executionInfo":{"status":"ok","timestamp":1668261161494,"user_tz":-330,"elapsed":6,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["labels = train_labels_csv[\"label\"].to_numpy() # convert labels column to NumPy array (from Training Dataset)\n","# Finding the unique labels\n","unique_labels = np.unique(labels)\n","# Turn every label into a boolean array\n","boolean_labels = [label == np.array(unique_labels) for label in labels]\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"2yeVv3pMKVWM","executionInfo":{"status":"ok","timestamp":1668261180473,"user_tz":-330,"elapsed":18984,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["# Create pathnames from image ID's\n","train_path = \"train/train/\"\n","filenames = [train_path + str(fname) + \".jpeg\" for fname in train_labels_csv[\"id\"]]      # Fetching training files' IDs from train_labels_csv\n","\n","val_path = \"validation/validation/\"\n","val_filenames = [val_path + str(fname) for fname in os.listdir(val_path)]       # Fetching Validation files' IDs from the validation set"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"jHQJsrvo5ndK","executionInfo":{"status":"ok","timestamp":1668261180473,"user_tz":-330,"elapsed":6,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["# Setup X & y variables\n","X = filenames\n","y = boolean_labels"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"dGGhJS5FKbVl","executionInfo":{"status":"ok","timestamp":1668261180474,"user_tz":-330,"elapsed":6,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["# Define image size\n","IMG_SIZE = 224\n","\n","def process_image(image_path):\n","  \"\"\"\n","  Takes an image file path and turns it into a Tensor.\n","  \"\"\"\n","  # Read in image file\n","  image = tf.io.read_file(image_path)\n","  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n","  image = tf.image.decode_jpeg(image, channels=3)\n","  # Convert the colour channel values from 0-225 values to 0-1 values\n","  image = tf.image.convert_image_dtype(image, tf.float32)\n","  # Resize the image to our desired size (224, 244)\n","  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n","  return image"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"NJEGS3j_Kk4N","executionInfo":{"status":"ok","timestamp":1668261180474,"user_tz":-330,"elapsed":6,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["# Create a simple function to return a tuple (image, label)\n","def get_image_label(image_path, label):\n","  \"\"\"\n","  Takes an image file path name and the associated label,\n","  processes the image and returns a tuple of (image, label).\n","  \"\"\"\n","  image = process_image(image_path)\n","  return image, label"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"7hqzeHeIKmc9","executionInfo":{"status":"ok","timestamp":1668261181986,"user_tz":-330,"elapsed":1518,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["# Define the batch size, 32 is a good default\n","BATCH_SIZE = 32\n","\n","# Create a function to turn data into batches\n","def create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n","  \"\"\"\n","  Creates batches of data out of image (x) and label (y) pairs.\n","  Shuffles the data if it's training data but doesn't shuffle it if it's validation data.\n","  Also accepts test data as input (no labels).\n","  \"\"\"\n","  # If the data is a test dataset, we probably don't have labels\n","  if test_data:\n","    print(\"Creating test data batches...\")\n","    data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # only filepaths\n","    data_batch = data.map(process_image).batch(BATCH_SIZE)\n","    return data_batch\n","  \n","  # If the data if a valid dataset, we don't need to shuffle it\n","  elif valid_data:\n","    print(\"Creating validation data batches...\")\n","    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n","                                               tf.constant(y))) # labels\n","    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n","    return data_batch\n","\n","  else:\n","    # If the data is a training dataset, we shuffle it\n","    print(\"Creating training data batches...\")\n","    # Turn filepaths and labels into Tensors\n","    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n","                                              tf.constant(y))) # labels\n","    \n","\n","    # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n","    data = data.map(get_image_label)\n","\n","    # Turn the data into batches\n","    data_batch = data.batch(BATCH_SIZE)\n","  return data_batch"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"E95RHTk_Kn3d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668261182599,"user_tz":-330,"elapsed":15,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"cbc6af09-56b8-4d1e-8115-d05d0a0ba938"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating training data batches...\n"]}],"source":["# Turn full training data in a data batch\n","full_data = create_data_batches(X, y)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"J4G6G1QOKo6N","executionInfo":{"status":"ok","timestamp":1668261182599,"user_tz":-330,"elapsed":12,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["# Setup input shape to the model\n","INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] # batch, height, width, colour channels\n","\n","# Setup output shape of the model\n","OUTPUT_SHAPE = len(unique_labels) # number of unique labels\n","\n","# Setup model URL from TensorFlow Hub\n","# MODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\"\n","# MODEL_URL =\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/classification/2\"\n","MODEL_URL =\"https://tfhub.dev/google/supcon/resnet_v1_200/imagenet/classification/1\"\n"]},{"cell_type":"code","source":["# # ONLY FOR DENSE-NETS\n","# import keras\n","# from keras.models import Model\n","# from keras.layers import Conv2D, MaxPooling2D, Dense, Input, Activation, Dropout, GlobalAveragePooling2D, BatchNormalization, concatenate, AveragePooling2D\n","# from keras.optimizers import Adam\n","\n","\n","\n","# def conv_layer(conv_x, filters):\n","#     conv_x = BatchNormalization()(conv_x)\n","#     conv_x = Activation('relu')(conv_x)\n","#     conv_x = Conv2D(filters, (3, 3), kernel_initializer='he_uniform', padding='same', use_bias=False)(conv_x)\n","#     conv_x = Dropout(0.2)(conv_x)\n","\n","#     return conv_x\n","\n","\n","# def dense_block(block_x, filters, growth_rate, layers_in_block):\n","#     for i in range(layers_in_block):\n","#         each_layer = conv_layer(block_x, growth_rate)\n","#         block_x = concatenate([block_x, each_layer], axis=-1)\n","#         filters += growth_rate\n","\n","#     return block_x, filters\n","\n","\n","# def transition_block(trans_x, tran_filters):\n","#     trans_x = BatchNormalization()(trans_x)\n","#     trans_x = Activation('relu')(trans_x)\n","#     trans_x = Conv2D(tran_filters, (1, 1), kernel_initializer='he_uniform', padding='same', use_bias=False)(trans_x)\n","#     trans_x = AveragePooling2D((2, 2), strides=(2, 2))(trans_x)\n","\n","#     return trans_x, tran_filters\n","\n","\n","# def dense_net(filters, growth_rate, classes, dense_block_size, layers_in_block):\n","#     input_img = Input(shape=(224, 224, 3))\n","#     x = Conv2D(24, (3, 3), kernel_initializer='he_uniform', padding='same', use_bias=False)(input_img)\n","\n","#     dense_x = BatchNormalization()(x)\n","#     dense_x = Activation('relu')(x)\n","\n","#     dense_x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(dense_x)\n","#     for block in range(dense_block_size - 1):\n","#         dense_x, filters = dense_block(dense_x, filters, growth_rate, layers_in_block)\n","#         dense_x, filters = transition_block(dense_x, filters)\n","\n","#     dense_x, filters = dense_block(dense_x, filters, growth_rate, layers_in_block)\n","#     dense_x = BatchNormalization()(dense_x)\n","#     dense_x = Activation('relu')(dense_x)\n","#     dense_x = GlobalAveragePooling2D()(dense_x)\n","\n","#     output = Dense(classes, activation='softmax')(dense_x)\n","\n","#     return Model(input_img, output)"],"metadata":{"id":"5bYCzeRpyMB-","executionInfo":{"status":"ok","timestamp":1668261182600,"user_tz":-330,"elapsed":12,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{"id":"TYIutERlKrIH","executionInfo":{"status":"ok","timestamp":1668261182600,"user_tz":-330,"elapsed":11,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["# we will build the model using the Keras API\n","\n","def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):\n","  print(\"Building the model with:\", MODEL_URL)\n","\n","  # Setup the model layers\n","  model = tf.keras.Sequential([\n","    hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n","    tf.keras.layers.Dense(units=OUTPUT_SHAPE, \n","                          activation=\"softmax\") # Layer 2 (output layer). Softmax will predict the probabilities for each class for each image\n","  ])\n","\n","  # Compile the model\n","  model.compile(\n","      loss=tf.keras.losses.CategoricalCrossentropy(), # Our model wants to reduce this (how wrong its guesses are)\n","      optimizer=tf.keras.optimizers.Adam(), # An optimizer helping our model how to improve its guesses\n","      metrics=[\"accuracy\"] # We'd like this to go up\n","  )\n","\n","  # Build the model\n","  model.build(INPUT_SHAPE) # Let the model know what kind of inputs it'll be getting\n","  \n","  return model"]},{"cell_type":"markdown","metadata":{"id":"TQ5fZFDQ4gw5"},"source":["## Creating the Model 2 for Full data Training"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"D0Mvji6nKscJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668261203819,"user_tz":-330,"elapsed":21229,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"034646ca-9112-4d86-a19a-920dfb0d4694"},"outputs":[{"output_type":"stream","name":"stdout","text":["Building the model with: https://tfhub.dev/google/supcon/resnet_v1_200/imagenet/classification/1\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," keras_layer (KerasLayer)    (None, 1000)              65111976  \n","                                                                 \n"," dense (Dense)               (None, 16)                16016     \n","                                                                 \n","=================================================================\n","Total params: 65,127,992\n","Trainable params: 16,016\n","Non-trainable params: 65,111,976\n","_________________________________________________________________\n"]}],"source":["# # Instantiate a new model for training on the full dataset\n","full_model2 = create_model()\n","full_model2.summary()"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"WNLYMgjtuhqA","executionInfo":{"status":"ok","timestamp":1668261203819,"user_tz":-330,"elapsed":19,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","import datetime\n","\n","# Create a function to build a TensorBoard callback\n","def create_tensorboard_callback():\n","  # Create a log directory for storing TensorBoard logs\n","  logdir = os.path.join(\"logs\",\n","                        # Make it so the logs get tracked whenever we run an experiment\n","                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","  return tf.keras.callbacks.TensorBoard(logdir)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"fnhQKzX8KuM8","executionInfo":{"status":"ok","timestamp":1668261203819,"user_tz":-330,"elapsed":18,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["# Create full model callbacks\n","\n","# TensorBoard callback\n","full_model_tensorboard = create_tensorboard_callback()\n","\n","# Early stopping callback\n","# Note: No validation set when training on all the data, so we monitor only training accuracy\n","full_model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",\n","                                                             patience=4)\n","\n","logger= tf.keras.callbacks.CSVLogger(\"res-net-logger.csv\")"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"5HVZ9qF5MrvZ","executionInfo":{"status":"ok","timestamp":1668261203819,"user_tz":-330,"elapsed":18,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["def save_model(model, suffix=None):\n","  \"\"\"\n","  Saves a given model in a models directory and appends a suffix (str)\n","  for clarity and reuse.\n","  \"\"\"\n","  # Create model directory with current time\n","  modeldir = os.path.join(\"models_archit\",\n","                          datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n","  model_path = modeldir + \"-\" + suffix + \".h5\" # save format of model\n","  print(f\"Saving model to: {model_path}...\")\n","  model.save(model_path)\n","  return model_path"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"Y8u-65LpMt0w","executionInfo":{"status":"ok","timestamp":1668261203820,"user_tz":-330,"elapsed":19,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["def load_model(model_path):\n","  \"\"\"\n","  Loads a saved model from a specified path.\n","  \"\"\"\n","  print(f\"Loading saved model from: {model_path}\")\n","  model = tf.keras.models.load_model(model_path,\n","                                     custom_objects={\"KerasLayer\":hub.KerasLayer})\n","  return model"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"02CIR-wyQ8sr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d8ff4f42-3b9a-4cfe-d7f6-c0aebe8d6e34","executionInfo":{"status":"ok","timestamp":1668266109581,"user_tz":-330,"elapsed":4355330,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","500/500 [==============================] - 3559s 7s/step - loss: 2.0853 - accuracy: 0.3432\n","Epoch 2/5\n","500/500 [==============================] - 187s 373ms/step - loss: 1.8619 - accuracy: 0.4129\n","Epoch 3/5\n","500/500 [==============================] - 187s 373ms/step - loss: 1.7968 - accuracy: 0.4333\n","Epoch 4/5\n","500/500 [==============================] - 186s 372ms/step - loss: 1.7570 - accuracy: 0.4476\n","Epoch 5/5\n","500/500 [==============================] - 186s 371ms/step - loss: 1.7283 - accuracy: 0.4563\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ff5cebcd350>"]},"metadata":{},"execution_count":23}],"source":["# Fit the full model to the full training data\n","full_model2.fit(x=full_data,\n","               epochs=5,\n","               callbacks=[full_model_tensorboard, \n","                          full_model_early_stopping, logger])"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"HI4SVAQaMwXV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668266111587,"user_tz":-330,"elapsed":2013,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"bdf88539-4d45-4535-e852-7338c0816d2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Saving model to: models_archit/20221112-15151668266108-res-net.h5...\n"]}],"source":["# Save our model trained on 4000 images from the Training Dataset\n","# save_model(full_model2, suffix=\"res-net\")\n","x=save_model(full_model2, suffix=\"res-net\")"]},{"cell_type":"code","source":["# check train and test data size"],"metadata":{"id":"sCf_IBZ1BIlc","executionInfo":{"status":"ok","timestamp":1668266111588,"user_tz":-330,"elapsed":11,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","execution_count":26,"metadata":{"id":"CNmB7eYIMywr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668266128168,"user_tz":-330,"elapsed":16590,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"e0c1cf28-835d-4e6e-fbec-ca9e5aac0e3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading saved model from: models_archit/20221112-15151668266108-res-net.h5\n"]}],"source":["# Load our model trained on 1000 images\n","# loaded_model = load_model('models_archit/20221112-02251668219959-res-net.h5')\n","loaded_model = load_model(x)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"VUgnLfpV9Wme","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668266128169,"user_tz":-330,"elapsed":35,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"3d84c1d7-4e2e-4f51-9e31-791bde6af3ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating validation data batches...\n"]}],"source":["X_val = X[:500]\n","y_val = y[:500]\n","val_data = create_data_batches(X_val, y_val, valid_data=True)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"DgffU6nG94Mm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668266139521,"user_tz":-330,"elapsed":11358,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"02de3a10-6208-4150-8822-fc1657a29a05"},"outputs":[{"output_type":"stream","name":"stdout","text":["16/16 [==============================] - 11s 491ms/step - loss: 1.6645 - accuracy: 0.4860\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.6644891500473022, 0.4860000014305115]"]},"metadata":{},"execution_count":28}],"source":["# Evaluate the loaded model\n","loaded_model.evaluate(val_data)"]},{"cell_type":"code","source":["predictions = loaded_model.predict(val_data, verbose=1) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tslYVCvFZTfu","executionInfo":{"status":"ok","timestamp":1668266152399,"user_tz":-330,"elapsed":12892,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"ded248f4-ed8d-4f41-ad6e-418a00aa40b9"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["16/16 [==============================] - 9s 363ms/step\n"]}]},{"cell_type":"code","source":["predictions.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m81HAQAMZuVF","executionInfo":{"status":"ok","timestamp":1668266152400,"user_tz":-330,"elapsed":8,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"46f71b46-31d3-48ac-be44-5e9608399684"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(500, 16)"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["predictions=pd.DataFrame(predictions)\n","predictions.to_csv('drive/MyDrive/Datathon/approx_predicted_label_res-net.csv')"],"metadata":{"id":"wYdDjvY2aFNE","executionInfo":{"status":"ok","timestamp":1668266153534,"user_tz":-330,"elapsed":1140,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","execution_count":32,"metadata":{"id":"bfQwWQmi-9ee","executionInfo":{"status":"ok","timestamp":1668266153535,"user_tz":-330,"elapsed":14,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["# # Turn prediction probabilities into their labels (Document Types)\n","# def get_pred_label(prediction_probabilities):\n","#   \"\"\"\n","#   Turns an array of prediction probabilities into a label.\n","#   \"\"\"\n","#   return unique_labels[np.argmax(prediction_probabilities)]\n"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"Jh7rKKQFGefG","executionInfo":{"status":"ok","timestamp":1668266153535,"user_tz":-330,"elapsed":13,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["# model_path = \"models_archit/20221112-00031668211416-efficient-net.h5\" \n","# data_path = \"validation/validation\""]},{"cell_type":"code","execution_count":34,"metadata":{"id":"7U88mvoxGc6q","executionInfo":{"status":"ok","timestamp":1668266153535,"user_tz":-330,"elapsed":13,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["# # Function to test the validation data stored in 'data_path' with the model stored in 'model_path'\n","# # here, model_path = \"drive/MyDrive/Datathon/models/20221007-08281665131319-full-trained-adam.h5\" \n","# #       data_path = \"drive/MyDrive/Datathon/validation/validation\"\n","\n","# def test(model_path, data_path):\n","#   # Load the fully trained model\n","#   loaded_full_model = load_model(model_path)\n","\n","#   # Load validation image filenames\n","#   val_path = data_path\n","#   val_filenames = [val_path + fname for fname in os.listdir(val_path)]\n","\n","#   # Getting the list of validation set IDs\n","#   val_id = [id for id in os.listdir(val_path)]\n","#   val_ids = []\n","#   for item in val_id:\n","#     val_ids.append(int(item.split(\".\")[0]))\n","  \n","#   # Create validation data batch so as to turn it into tensors and then fit it in our model\n","#   val_data = create_data_batches(val_filenames, test_data=True) \n","\n","#   # Make predictions on the validation data \n","#   predictions = loaded_full_model.predict(val_data, verbose=1) \n","  \n","#   # Getting the predicted labels in array val_pred_labels[]\n","#   val_pred_labels = []\n","#   for i in range(len(val_ids)):\n","#     val_pred_labels.append(get_pred_label(predictions[i]))\n","  \n","#   # Fitting the data into Pandas dataframe\n","#   data = []\n","#   for i in range(len(val_ids)):\n","#     data.append((val_ids[i], val_pred_labels[i]))\n","#   df = pd.DataFrame(data, columns=['id','label'])\n","\n","#   # Saving the predicted labels on validation set images in CSV\n","#   # Saving the predictions to predicted_label.csv file and saving it inside the datathon folder in GDrive\n","#   # df.to_csv(r'drive/MyDrive/Datathon/predicted_label2.csv', index=False)\n","\n","#   df.to_csv(r'predicted_label_mobile-net.csv', index=False)  \n","#   # df.to_csv(r'predicted_label_efficient-net.csv', index=False)  "]},{"cell_type":"code","execution_count":35,"metadata":{"id":"mhmWn7z10bh3","executionInfo":{"status":"ok","timestamp":1668266153536,"user_tz":-330,"elapsed":14,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["# test(model_path, data_path)"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"W48rem9SGj9L","executionInfo":{"status":"ok","timestamp":1668266153536,"user_tz":-330,"elapsed":13,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}}},"outputs":[],"source":["# data= pd.read_csv('drive/MyDrive/Datathon/predicted_label.csv')\n","# data"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}