{"cells":[{"cell_type":"markdown","metadata":{"id":"RlZu1rxMt77N"},"source":["# For Training and Loading the Pretrained Model on a Fresh Dataset"]},{"cell_type":"code","execution_count":72,"metadata":{"id":"gkwITU5hFTpM","executionInfo":{"status":"ok","timestamp":1668281160342,"user_tz":-330,"elapsed":412,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from matplotlib.pyplot import imread\n","from keras.layers import Input\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","# import tf.keras.callbacks "]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1668281161254,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"},"user_tz":-330},"id":"ZyAYm1hIJ5AF","outputId":"a15bb9fd-7583-44a0-c923-bc09c543fd31"},"outputs":[{"output_type":"stream","name":"stdout","text":["TF version: 2.9.2\n","Hub version: 0.12.0\n","GPU available\n"]}],"source":["print(\"TF version:\", tf.__version__)\n","print(\"Hub version:\", hub.__version__)\n","\n","# Check for GPU\n","print(\"GPU\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"not available\")"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"9rcTFkleBhQb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668281164624,"user_tz":-330,"elapsed":3375,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}},"outputId":"a8797cc5-a0e0-4eca-fadf-f91af6d4e190"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}],"source":["# # Running this cell will provide you with a token to link your drive to this notebook\n","from google.colab import drive\n","import sys\n","\n","drive.mount('/content/gdrive/')\n","sys.path.append('/content/gdrive/My Drive/Datathon/')"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"wYX_zML-Bvwv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668281164624,"user_tz":-330,"elapsed":14,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}},"outputId":"169fa912-fcce-4ff9-e6f3-ffa9744b49cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/.shortcut-targets-by-id/18Pjuiby86W8tPsgJuQAMo0AMjzsG0pLw/Datathon\n"]}],"source":["%cd '/content/gdrive/My Drive/Datathon/'"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"Ay8RDA8iB7lZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668281165089,"user_tz":-330,"elapsed":474,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}},"outputId":"10b78037-22da-44ed-8aba-8a74b7f48942"},"outputs":[{"output_type":"stream","name":"stdout","text":[" Datathon2.ipynb\t\t        models_archit\n"," datathonindoml-2022.zip\t       'New Models.ipynb'\n"," dense-net-logger.csv\t\t        predicted_label_3.csv\n"," drive\t\t\t\t        predicted_label.csv\n"," efficient-net-logger.csv\t       'rekhani LSTM.ipynb'\n","'for RESNETS.ipynb'\t\t        res-net-logger.csv\n"," kaggle-indoml-submission.csv\t        sample_submission.csv\n"," kaggle-indoml-submission-model-2.csv   train\n"," logs\t\t\t\t        train_labels.csv\n"," mobile-net-logger.csv\t\t        validation\n"," mobile-net-logger.gsheet\t       'Vision Transformers.ipynb'\n"," models\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":77,"metadata":{"id":"tO79ce92J6hH","executionInfo":{"status":"ok","timestamp":1668281165090,"user_tz":-330,"elapsed":12,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["train_labels_csv = pd.read_csv(\"train_labels.csv\")"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"fDXtkZfjKF-H","executionInfo":{"status":"ok","timestamp":1668281165090,"user_tz":-330,"elapsed":11,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["labels = train_labels_csv[\"label\"].to_numpy() # convert labels column to NumPy array (from Training Dataset)\n","# Finding the unique labels\n","unique_labels = np.unique(labels)\n","# Turn every label into a boolean array\n","boolean_labels = [label == np.array(unique_labels) for label in labels]\n"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"2yeVv3pMKVWM","executionInfo":{"status":"ok","timestamp":1668281165091,"user_tz":-330,"elapsed":12,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["# Create pathnames from image ID's\n","train_path = \"train/train/\"\n","filenames = [train_path + str(fname) + \".jpeg\" for fname in train_labels_csv[\"id\"]]      # Fetching training files' IDs from train_labels_csv\n","\n","val_path = \"validation/validation/\"\n","val_filenames = [val_path + str(fname) for fname in os.listdir(val_path)]       # Fetching Validation files' IDs from the validation set"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"jHQJsrvo5ndK","executionInfo":{"status":"ok","timestamp":1668281165091,"user_tz":-330,"elapsed":11,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["# Setup X & y variables\n","X = filenames\n","y = boolean_labels"]},{"cell_type":"code","execution_count":81,"metadata":{"id":"dGGhJS5FKbVl","executionInfo":{"status":"ok","timestamp":1668281165092,"user_tz":-330,"elapsed":12,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["# Define image size\n","# IMG_SIZE = 224\n","IMG_SIZE = 256\n","\n","def process_image(image_path):\n","  \"\"\"\n","  Takes an image file path and turns it into a Tensor.\n","  \"\"\"\n","  # Read in image file\n","  image = tf.io.read_file(image_path)\n","  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n","  image = tf.image.decode_jpeg(image, channels=3)\n","  # Convert the colour channel values from 0-225 values to 0-1 values\n","  image = tf.image.convert_image_dtype(image, tf.float32)\n","  # Resize the image to our desired size (224, 244)\n","  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n","  return image"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"NJEGS3j_Kk4N","executionInfo":{"status":"ok","timestamp":1668281165092,"user_tz":-330,"elapsed":12,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["# Create a simple function to return a tuple (image, label)\n","def get_image_label(image_path, label):\n","  \"\"\"\n","  Takes an image file path name and the associated label,\n","  processes the image and returns a tuple of (image, label).\n","  \"\"\"\n","  image = process_image(image_path)\n","  return image, label"]},{"cell_type":"code","execution_count":83,"metadata":{"id":"7hqzeHeIKmc9","executionInfo":{"status":"ok","timestamp":1668281165092,"user_tz":-330,"elapsed":12,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["# Define the batch size, 32 is a good default\n","BATCH_SIZE = 32\n","\n","# Create a function to turn data into batches\n","def create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n","  \"\"\"\n","  Creates batches of data out of image (x) and label (y) pairs.\n","  Shuffles the data if it's training data but doesn't shuffle it if it's validation data.\n","  Also accepts test data as input (no labels).\n","  \"\"\"\n","  # If the data is a test dataset, we probably don't have labels\n","  if test_data:\n","    print(\"Creating test data batches...\")\n","    data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # only filepaths\n","    data_batch = data.map(process_image).batch(BATCH_SIZE)\n","    return data_batch\n","  \n","  # If the data if a valid dataset, we don't need to shuffle it\n","  elif valid_data:\n","    print(\"Creating validation data batches...\")\n","    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n","                                               tf.constant(y))) # labels\n","    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n","    return data_batch\n","\n","  else:\n","    # If the data is a training dataset, we shuffle it\n","    print(\"Creating training data batches...\")\n","    # Turn filepaths and labels into Tensors\n","    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n","                                              tf.constant(y))) # labels\n","    \n","\n","    # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n","    data = data.map(get_image_label)\n","\n","    # Turn the data into batches\n","    data_batch = data.batch(BATCH_SIZE)\n","  return data_batch"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"E95RHTk_Kn3d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668281165092,"user_tz":-330,"elapsed":11,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}},"outputId":"192f035e-2e95-4264-86ce-febe2a15111a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating training data batches...\n"]}],"source":["# Turn full training data in a data batch\n","full_data = create_data_batches(X, y)"]},{"cell_type":"code","execution_count":85,"metadata":{"id":"J4G6G1QOKo6N","executionInfo":{"status":"ok","timestamp":1668281165093,"user_tz":-330,"elapsed":11,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["# Setup input shape to the model\n","INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] # batch, height, width, colour channels\n","\n","# Setup output shape of the model\n","OUTPUT_SHAPE = len(unique_labels) # number of unique labels\n","\n","# Setup model URL from TensorFlow Hub\n","# MODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\"\n","# MODEL_URL =\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/classification/2\"\n","# MODEL_URL =\"https://tfhub.dev/google/supcon/resnet_v1_200/imagenet/classification/1\"\n","MODEL_URL =\"https://tfhub.dev/sayannath/mobilevit_s_1k_256_fe/1\"\n"]},{"cell_type":"code","execution_count":99,"metadata":{"id":"TYIutERlKrIH","executionInfo":{"status":"ok","timestamp":1668281789953,"user_tz":-330,"elapsed":3,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["# we will build the model using the Keras API\n","\n","def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):\n","  print(\"Building the model with:\", MODEL_URL)\n","\n","  # Setup the model layers\n","  model = tf.keras.Sequential([\n","    hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(units=OUTPUT_SHAPE, \n","                          activation=\"softmax\") # Layer 2 (output layer). Softmax will predict the probabilities for each class for each image\n","  ])\n","  # Compile the model\n","  model.compile(\n","      loss=tf.keras.losses.CategoricalCrossentropy(), # Our model wants to reduce this (how wrong its guesses are)\n","      optimizer=tf.keras.optimizers.Adam(), # An optimizer helping our model how to improve its guesses\n","      metrics=[\"accuracy\"] # We'd like this to go up\n","  )\n","\n","  # Build the model\n","  model.build(INPUT_SHAPE) # Let the model know what kind of inputs it'll be getting\n","  print(\"YELLLO\")\n","  \n","  return model"]},{"cell_type":"markdown","metadata":{"id":"TQ5fZFDQ4gw5"},"source":["## Creating the Model 2 for Full data Training"]},{"cell_type":"code","execution_count":100,"metadata":{"id":"D0Mvji6nKscJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668281803142,"user_tz":-330,"elapsed":12327,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}},"outputId":"6941446a-4291-44e4-c1c0-03b90a8513fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Building the model with: https://tfhub.dev/sayannath/mobilevit_s_1k_256_fe/1\n","YELLLO\n","Model: \"sequential_10\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," keras_layer_11 (KerasLayer)  (None, 8, 8, 640)        4949888   \n","                                                                 \n"," flatten_2 (Flatten)         (None, 40960)             0         \n","                                                                 \n"," dense_11 (Dense)            (None, 16)                655376    \n","                                                                 \n","=================================================================\n","Total params: 5,605,264\n","Trainable params: 655,376\n","Non-trainable params: 4,949,888\n","_________________________________________________________________\n"]}],"source":["# # Instantiate a new model for training on the full dataset\n","full_model2 = create_model()\n","full_model2.summary()"]},{"cell_type":"code","execution_count":101,"metadata":{"id":"WNLYMgjtuhqA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668281803142,"user_tz":-330,"elapsed":18,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}},"outputId":"fc66d10a-ae20-4e18-d70d-e77afc1d5020"},"outputs":[{"output_type":"stream","name":"stdout","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"]}],"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","import datetime\n","\n","# Create a function to build a TensorBoard callback\n","def create_tensorboard_callback():\n","  # Create a log directory for storing TensorBoard logs\n","  logdir = os.path.join(\"logs\",\n","                        # Make it so the logs get tracked whenever we run an experiment\n","                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","  return tf.keras.callbacks.TensorBoard(logdir)"]},{"cell_type":"code","execution_count":102,"metadata":{"id":"fnhQKzX8KuM8","executionInfo":{"status":"ok","timestamp":1668281803143,"user_tz":-330,"elapsed":17,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["# Create full model callbacks\n","\n","# TensorBoard callback\n","full_model_tensorboard = create_tensorboard_callback()\n","\n","# Early stopping callback\n","# Note: No validation set when training on all the data, so we monitor only training accuracy\n","full_model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",\n","                                                             patience=4)\n","\n","logger= tf.keras.callbacks.CSVLogger(\"vision-trans-logger.csv\")"]},{"cell_type":"code","execution_count":103,"metadata":{"id":"5HVZ9qF5MrvZ","executionInfo":{"status":"ok","timestamp":1668281803143,"user_tz":-330,"elapsed":16,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["def save_model(model, suffix=None):\n","  \"\"\"\n","  Saves a given model in a models directory and appends a suffix (str)\n","  for clarity and reuse.\n","  \"\"\"\n","  # Create model directory with current time\n","  modeldir = os.path.join(\"models_archit\",\n","                          datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n","  model_path = modeldir + \"-\" + suffix + \".h5\" # save format of model\n","  print(f\"Saving model to: {model_path}...\")\n","  model.save(model_path)\n","  return model_path"]},{"cell_type":"code","execution_count":104,"metadata":{"id":"Y8u-65LpMt0w","executionInfo":{"status":"ok","timestamp":1668281803143,"user_tz":-330,"elapsed":16,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["def load_model(model_path):\n","  \"\"\"\n","  Loads a saved model from a specified path.\n","  \"\"\"\n","  print(f\"Loading saved model from: {model_path}\")\n","  model = tf.keras.models.load_model(model_path,\n","                                     custom_objects={\"KerasLayer\":hub.KerasLayer})\n","  return model"]},{"cell_type":"code","execution_count":105,"metadata":{"id":"02CIR-wyQ8sr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7f100d44-6a70-43c3-c566-fd9a0092c319","executionInfo":{"status":"ok","timestamp":1668284006492,"user_tz":-330,"elapsed":2203365,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","500/500 [==============================] - 1657s 3s/step - loss: 2.8738 - accuracy: 0.5265\n","Epoch 2/5\n","500/500 [==============================] - 134s 267ms/step - loss: 2.0708 - accuracy: 0.6416\n","Epoch 3/5\n","500/500 [==============================] - 125s 251ms/step - loss: 1.8641 - accuracy: 0.6830\n","Epoch 4/5\n","500/500 [==============================] - 121s 241ms/step - loss: 1.8469 - accuracy: 0.7064\n","Epoch 5/5\n","500/500 [==============================] - 121s 241ms/step - loss: 1.6887 - accuracy: 0.7387\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7febf87b6310>"]},"metadata":{},"execution_count":105}],"source":["# Fit the full model to the full training data\n","full_model2.fit(x=full_data,\n","               epochs=5,\n","               callbacks=[full_model_tensorboard, \n","                          full_model_early_stopping, logger])"]},{"cell_type":"code","execution_count":106,"metadata":{"id":"HI4SVAQaMwXV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668284007176,"user_tz":-330,"elapsed":699,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}},"outputId":"f5dd3202-cac9-42b4-f11e-ea1c7fa7e470"},"outputs":[{"output_type":"stream","name":"stdout","text":["Saving model to: models_archit/20221112-20131668284006-vision-trans.h5...\n"]}],"source":["# Save our model trained on 4000 images from the Training Dataset\n","# save_model(full_model2, suffix=\"res-net\")\n","x=save_model(full_model2, suffix=\"vision-trans\")"]},{"cell_type":"code","source":["# check train and test data size"],"metadata":{"id":"sCf_IBZ1BIlc","executionInfo":{"status":"ok","timestamp":1668284007177,"user_tz":-330,"elapsed":5,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"execution_count":107,"outputs":[]},{"cell_type":"code","execution_count":108,"metadata":{"id":"CNmB7eYIMywr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668284019622,"user_tz":-330,"elapsed":12449,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}},"outputId":"a44e5407-fb91-484e-8067-586fc25e58f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading saved model from: models_archit/20221112-20131668284006-vision-trans.h5\n"]}],"source":["# Load our model trained on 1000 images\n","# loaded_model = load_model('models_archit/20221112-02251668219959-res-net.h5')\n","loaded_model = load_model(x)"]},{"cell_type":"code","execution_count":109,"metadata":{"id":"VUgnLfpV9Wme","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668284019622,"user_tz":-330,"elapsed":17,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}},"outputId":"9ca7c3c9-ab5c-423a-fdf4-6afe39712438"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating validation data batches...\n"]}],"source":["X_val = X[:500]\n","y_val = y[:500]\n","val_data = create_data_batches(X_val, y_val, valid_data=True)"]},{"cell_type":"code","execution_count":110,"metadata":{"id":"DgffU6nG94Mm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668284025453,"user_tz":-330,"elapsed":5847,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}},"outputId":"a3ee09c1-6213-4a5c-f158-6f51e358b690"},"outputs":[{"output_type":"stream","name":"stdout","text":["16/16 [==============================] - 6s 268ms/step - loss: 1.4593 - accuracy: 0.7360\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.4592727422714233, 0.7360000014305115]"]},"metadata":{},"execution_count":110}],"source":["# Evaluate the loaded model\n","loaded_model.evaluate(val_data)"]},{"cell_type":"code","source":["predictions = loaded_model.predict(val_data, verbose=1) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tslYVCvFZTfu","executionInfo":{"status":"ok","timestamp":1668284030343,"user_tz":-330,"elapsed":4905,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}},"outputId":"5fcb3e29-8f13-4958-d0b7-51a7972df1fb"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["16/16 [==============================] - 5s 227ms/step\n"]}]},{"cell_type":"code","source":["predictions.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m81HAQAMZuVF","executionInfo":{"status":"ok","timestamp":1668284030344,"user_tz":-330,"elapsed":15,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}},"outputId":"90337db6-46a1-4aa6-9c50-ecf21a0de117"},"execution_count":112,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(500, 16)"]},"metadata":{},"execution_count":112}]},{"cell_type":"code","source":["predictions=pd.DataFrame(predictions)\n","predictions.to_csv('drive/MyDrive/Datathon/approx_predicted_label_vision-trans.csv')"],"metadata":{"id":"wYdDjvY2aFNE","executionInfo":{"status":"ok","timestamp":1668284031131,"user_tz":-330,"elapsed":801,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"execution_count":113,"outputs":[]},{"cell_type":"code","execution_count":114,"metadata":{"id":"bfQwWQmi-9ee","executionInfo":{"status":"ok","timestamp":1668284031131,"user_tz":-330,"elapsed":6,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["# # Turn prediction probabilities into their labels (Document Types)\n","# def get_pred_label(prediction_probabilities):\n","#   \"\"\"\n","#   Turns an array of prediction probabilities into a label.\n","#   \"\"\"\n","#   return unique_labels[np.argmax(prediction_probabilities)]\n"]},{"cell_type":"code","execution_count":115,"metadata":{"id":"Jh7rKKQFGefG","executionInfo":{"status":"ok","timestamp":1668284031132,"user_tz":-330,"elapsed":7,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["# model_path = \"models_archit/20221112-00031668211416-efficient-net.h5\" \n","# data_path = \"validation/validation\""]},{"cell_type":"code","execution_count":116,"metadata":{"id":"7U88mvoxGc6q","executionInfo":{"status":"ok","timestamp":1668284031132,"user_tz":-330,"elapsed":7,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["# # Function to test the validation data stored in 'data_path' with the model stored in 'model_path'\n","# # here, model_path = \"drive/MyDrive/Datathon/models/20221007-08281665131319-full-trained-adam.h5\" \n","# #       data_path = \"drive/MyDrive/Datathon/validation/validation\"\n","\n","# def test(model_path, data_path):\n","#   # Load the fully trained model\n","#   loaded_full_model = load_model(model_path)\n","\n","#   # Load validation image filenames\n","#   val_path = data_path\n","#   val_filenames = [val_path + fname for fname in os.listdir(val_path)]\n","\n","#   # Getting the list of validation set IDs\n","#   val_id = [id for id in os.listdir(val_path)]\n","#   val_ids = []\n","#   for item in val_id:\n","#     val_ids.append(int(item.split(\".\")[0]))\n","  \n","#   # Create validation data batch so as to turn it into tensors and then fit it in our model\n","#   val_data = create_data_batches(val_filenames, test_data=True) \n","\n","#   # Make predictions on the validation data \n","#   predictions = loaded_full_model.predict(val_data, verbose=1) \n","  \n","#   # Getting the predicted labels in array val_pred_labels[]\n","#   val_pred_labels = []\n","#   for i in range(len(val_ids)):\n","#     val_pred_labels.append(get_pred_label(predictions[i]))\n","  \n","#   # Fitting the data into Pandas dataframe\n","#   data = []\n","#   for i in range(len(val_ids)):\n","#     data.append((val_ids[i], val_pred_labels[i]))\n","#   df = pd.DataFrame(data, columns=['id','label'])\n","\n","#   # Saving the predicted labels on validation set images in CSV\n","#   # Saving the predictions to predicted_label.csv file and saving it inside the datathon folder in GDrive\n","#   # df.to_csv(r'drive/MyDrive/Datathon/predicted_label2.csv', index=False)\n","\n","#   df.to_csv(r'predicted_label_mobile-net.csv', index=False)  \n","#   # df.to_csv(r'predicted_label_efficient-net.csv', index=False)  "]},{"cell_type":"code","execution_count":117,"metadata":{"id":"mhmWn7z10bh3","executionInfo":{"status":"ok","timestamp":1668284031132,"user_tz":-330,"elapsed":7,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["# test(model_path, data_path)"]},{"cell_type":"code","execution_count":118,"metadata":{"id":"W48rem9SGj9L","executionInfo":{"status":"ok","timestamp":1668284031132,"user_tz":-330,"elapsed":6,"user":{"displayName":"Archit Mangrulkar","userId":"15077082084364612857"}}},"outputs":[],"source":["# data= pd.read_csv('drive/MyDrive/Datathon/predicted_label.csv')\n","# data"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}