{"cells":[{"cell_type":"markdown","metadata":{"id":"RlZu1rxMt77N"},"source":["# For Training and Loading the Pretrained Model on a Fresh Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gkwITU5hFTpM"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from matplotlib.pyplot import imread\n","from keras.layers import Input\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","# import tf.keras.callbacks "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1668240653021,"user":{"displayName":"totally reliable","userId":"15953242274047744585"},"user_tz":-330},"id":"ZyAYm1hIJ5AF","outputId":"6d2cb2af-8f7c-4a83-dc97-08db3d1e90fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["TF version: 2.9.2\n","Hub version: 0.12.0\n","GPU available\n"]}],"source":["print(\"TF version:\", tf.__version__)\n","print(\"Hub version:\", hub.__version__)\n","\n","# Check for GPU\n","print(\"GPU\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"not available\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9rcTFkleBhQb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668240657002,"user_tz":-330,"elapsed":3992,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"d202b180-a572-4ff6-9502-be4d442ba308"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}],"source":["# # Running this cell will provide you with a token to link your drive to this notebook\n","from google.colab import drive\n","import sys\n","\n","drive.mount('/content/gdrive/')\n","sys.path.append('/content/gdrive/My Drive/Datathon/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wYX_zML-Bvwv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668240657003,"user_tz":-330,"elapsed":15,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"00329871-b1d3-4387-ef80-02a1a2e4689a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/.shortcut-targets-by-id/18Pjuiby86W8tPsgJuQAMo0AMjzsG0pLw/Datathon\n"]}],"source":["%cd '/content/gdrive/My Drive/Datathon/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ay8RDA8iB7lZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668240657003,"user_tz":-330,"elapsed":14,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"8f182f70-53c7-4b09-cfad-7ead020a9e0d"},"outputs":[{"output_type":"stream","name":"stdout","text":[" Datathon2.ipynb\t\t        models_archit\n"," datathonindoml-2022.zip\t       'New Models.ipynb'\n"," drive\t\t\t\t        predicted_label_3.csv\n"," efficient-net-logger.csv\t        predicted_label.csv\n"," kaggle-indoml-submission.csv\t        res-net-logger.csv\n"," kaggle-indoml-submission-model-2.csv   sample_submission.csv\n"," logs\t\t\t\t        train\n"," mobile-net-logger.csv\t\t        train_labels.csv\n"," mobile-net-logger.gsheet\t        validation\n"," models\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tO79ce92J6hH"},"outputs":[],"source":["train_labels_csv = pd.read_csv(\"train_labels.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fDXtkZfjKF-H"},"outputs":[],"source":["labels = train_labels_csv[\"label\"].to_numpy() # convert labels column to NumPy array (from Training Dataset)\n","# Finding the unique labels\n","unique_labels = np.unique(labels)\n","# Turn every label into a boolean array\n","boolean_labels = [label == np.array(unique_labels) for label in labels]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2yeVv3pMKVWM"},"outputs":[],"source":["# Create pathnames from image ID's\n","train_path = \"train/train/\"\n","filenames = [train_path + str(fname) + \".jpeg\" for fname in train_labels_csv[\"id\"]]      # Fetching training files' IDs from train_labels_csv\n","\n","val_path = \"validation/validation/\"\n","val_filenames = [val_path + str(fname) for fname in os.listdir(val_path)]       # Fetching Validation files' IDs from the validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jHQJsrvo5ndK"},"outputs":[],"source":["# Setup X & y variables\n","X = filenames\n","y = boolean_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dGGhJS5FKbVl"},"outputs":[],"source":["# Define image size\n","IMG_SIZE = 224\n","\n","def process_image(image_path):\n","  \"\"\"\n","  Takes an image file path and turns it into a Tensor.\n","  \"\"\"\n","  # Read in image file\n","  image = tf.io.read_file(image_path)\n","  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n","  image = tf.image.decode_jpeg(image, channels=3)\n","  # Convert the colour channel values from 0-225 values to 0-1 values\n","  image = tf.image.convert_image_dtype(image, tf.float32)\n","  # Resize the image to our desired size (224, 244)\n","  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n","  return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NJEGS3j_Kk4N"},"outputs":[],"source":["# Create a simple function to return a tuple (image, label)\n","def get_image_label(image_path, label):\n","  \"\"\"\n","  Takes an image file path name and the associated label,\n","  processes the image and returns a tuple of (image, label).\n","  \"\"\"\n","  image = process_image(image_path)\n","  return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7hqzeHeIKmc9"},"outputs":[],"source":["# Define the batch size, 32 is a good default\n","BATCH_SIZE = 32\n","\n","# Create a function to turn data into batches\n","def create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n","  \"\"\"\n","  Creates batches of data out of image (x) and label (y) pairs.\n","  Shuffles the data if it's training data but doesn't shuffle it if it's validation data.\n","  Also accepts test data as input (no labels).\n","  \"\"\"\n","  # If the data is a test dataset, we probably don't have labels\n","  if test_data:\n","    print(\"Creating test data batches...\")\n","    data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # only filepaths\n","    data_batch = data.map(process_image).batch(BATCH_SIZE)\n","    return data_batch\n","  \n","  # If the data if a valid dataset, we don't need to shuffle it\n","  elif valid_data:\n","    print(\"Creating validation data batches...\")\n","    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n","                                               tf.constant(y))) # labels\n","    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n","    return data_batch\n","\n","  else:\n","    # If the data is a training dataset, we shuffle it\n","    print(\"Creating training data batches...\")\n","    # Turn filepaths and labels into Tensors\n","    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n","                                              tf.constant(y))) # labels\n","    \n","\n","    # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n","    data = data.map(get_image_label)\n","\n","    # Turn the data into batches\n","    data_batch = data.batch(BATCH_SIZE)\n","  return data_batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E95RHTk_Kn3d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668240657005,"user_tz":-330,"elapsed":11,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"39d21870-f809-4ff9-beca-04a3b4f03566"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating training data batches...\n"]}],"source":["# Turn full training data in a data batch\n","full_data = create_data_batches(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J4G6G1QOKo6N"},"outputs":[],"source":["# Setup input shape to the model\n","INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] # batch, height, width, colour channels\n","\n","# Setup output shape of the model\n","OUTPUT_SHAPE = len(unique_labels) # number of unique labels\n","\n","# Setup model URL from TensorFlow Hub\n","# MODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\"\n","# MODEL_URL =\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/classification/2\"\n","# MODEL_URL =\"https://tfhub.dev/google/supcon/resnet_v1_200/imagenet/classification/1\"\n"]},{"cell_type":"code","source":["# ONLY FOR DENSE-NETS\n","import keras\n","from keras.models import Model\n","from keras.layers import Conv2D, MaxPooling2D, Dense, Input, Activation, Dropout, GlobalAveragePooling2D, BatchNormalization, concatenate, AveragePooling2D\n","from keras.optimizers import Adam\n","\n","\n","\n","def conv_layer(conv_x, filters):\n","    conv_x = BatchNormalization()(conv_x)\n","    conv_x = Activation('relu')(conv_x)\n","    conv_x = Conv2D(filters, (3, 3), kernel_initializer='he_uniform', padding='same', use_bias=False)(conv_x)\n","    conv_x = Dropout(0.2)(conv_x)\n","\n","    return conv_x\n","\n","\n","def dense_block(block_x, filters, growth_rate, layers_in_block):\n","    for i in range(layers_in_block):\n","        each_layer = conv_layer(block_x, growth_rate)\n","        block_x = concatenate([block_x, each_layer], axis=-1)\n","        filters += growth_rate\n","\n","    return block_x, filters\n","\n","\n","def transition_block(trans_x, tran_filters):\n","    trans_x = BatchNormalization()(trans_x)\n","    trans_x = Activation('relu')(trans_x)\n","    trans_x = Conv2D(tran_filters, (1, 1), kernel_initializer='he_uniform', padding='same', use_bias=False)(trans_x)\n","    trans_x = AveragePooling2D((2, 2), strides=(2, 2))(trans_x)\n","\n","    return trans_x, tran_filters\n","\n","\n","def dense_net(filters, growth_rate, classes, dense_block_size, layers_in_block):\n","    input_img = Input(shape=(224, 224, 3))\n","    x = Conv2D(24, (3, 3), kernel_initializer='he_uniform', padding='same', use_bias=False)(input_img)\n","\n","    dense_x = BatchNormalization()(x)\n","    dense_x = Activation('relu')(x)\n","\n","    dense_x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(dense_x)\n","    for block in range(dense_block_size - 1):\n","        dense_x, filters = dense_block(dense_x, filters, growth_rate, layers_in_block)\n","        dense_x, filters = transition_block(dense_x, filters)\n","\n","    dense_x, filters = dense_block(dense_x, filters, growth_rate, layers_in_block)\n","    dense_x = BatchNormalization()(dense_x)\n","    dense_x = Activation('relu')(dense_x)\n","    dense_x = GlobalAveragePooling2D()(dense_x)\n","\n","    output = Dense(classes, activation='softmax')(dense_x)\n","\n","    return Model(input_img, output)"],"metadata":{"id":"5bYCzeRpyMB-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TYIutERlKrIH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668240658004,"user_tz":-330,"elapsed":1008,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"88569ea8-90f6-40b0-e642-0494b84e961e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 224, 224, 24  648         ['input_2[0][0]']                \n","                                )                                                                 \n","                                                                                                  \n"," activation_16 (Activation)     (None, 224, 224, 24  0           ['conv2d_15[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d_1 (MaxPooling2D)  (None, 112, 112, 24  0          ['activation_16[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 112, 112, 24  96         ['max_pooling2d_1[0][0]']        \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_17 (Activation)     (None, 112, 112, 24  0           ['batch_normalization_17[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_16 (Conv2D)             (None, 112, 112, 12  2592        ['activation_17[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," dropout_12 (Dropout)           (None, 112, 112, 12  0           ['conv2d_16[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," concatenate_12 (Concatenate)   (None, 112, 112, 36  0           ['max_pooling2d_1[0][0]',        \n","                                )                                 'dropout_12[0][0]']             \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 112, 112, 36  144        ['concatenate_12[0][0]']         \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_18 (Activation)     (None, 112, 112, 36  0           ['batch_normalization_18[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_17 (Conv2D)             (None, 112, 112, 12  3888        ['activation_18[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," dropout_13 (Dropout)           (None, 112, 112, 12  0           ['conv2d_17[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," concatenate_13 (Concatenate)   (None, 112, 112, 48  0           ['concatenate_12[0][0]',         \n","                                )                                 'dropout_13[0][0]']             \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 112, 112, 48  192        ['concatenate_13[0][0]']         \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_19 (Activation)     (None, 112, 112, 48  0           ['batch_normalization_19[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 112, 112, 12  5184        ['activation_19[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," dropout_14 (Dropout)           (None, 112, 112, 12  0           ['conv2d_18[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," concatenate_14 (Concatenate)   (None, 112, 112, 60  0           ['concatenate_13[0][0]',         \n","                                )                                 'dropout_14[0][0]']             \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 112, 112, 60  240        ['concatenate_14[0][0]']         \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_20 (Activation)     (None, 112, 112, 60  0           ['batch_normalization_20[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 112, 112, 12  6480        ['activation_20[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," dropout_15 (Dropout)           (None, 112, 112, 12  0           ['conv2d_19[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," concatenate_15 (Concatenate)   (None, 112, 112, 72  0           ['concatenate_14[0][0]',         \n","                                )                                 'dropout_15[0][0]']             \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 112, 112, 72  288        ['concatenate_15[0][0]']         \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_21 (Activation)     (None, 112, 112, 72  0           ['batch_normalization_21[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 112, 112, 72  5184        ['activation_21[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," average_pooling2d_2 (AveragePo  (None, 56, 56, 72)  0           ['conv2d_20[0][0]']              \n"," oling2D)                                                                                         \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 56, 56, 72)  288         ['average_pooling2d_2[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_22 (Activation)     (None, 56, 56, 72)   0           ['batch_normalization_22[0][0]'] \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 56, 56, 12)   7776        ['activation_22[0][0]']          \n","                                                                                                  \n"," dropout_16 (Dropout)           (None, 56, 56, 12)   0           ['conv2d_21[0][0]']              \n","                                                                                                  \n"," concatenate_16 (Concatenate)   (None, 56, 56, 84)   0           ['average_pooling2d_2[0][0]',    \n","                                                                  'dropout_16[0][0]']             \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 56, 56, 84)  336         ['concatenate_16[0][0]']         \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_23 (Activation)     (None, 56, 56, 84)   0           ['batch_normalization_23[0][0]'] \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 56, 56, 12)   9072        ['activation_23[0][0]']          \n","                                                                                                  \n"," dropout_17 (Dropout)           (None, 56, 56, 12)   0           ['conv2d_22[0][0]']              \n","                                                                                                  \n"," concatenate_17 (Concatenate)   (None, 56, 56, 96)   0           ['concatenate_16[0][0]',         \n","                                                                  'dropout_17[0][0]']             \n","                                                                                                  \n"," batch_normalization_24 (BatchN  (None, 56, 56, 96)  384         ['concatenate_17[0][0]']         \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_24 (Activation)     (None, 56, 56, 96)   0           ['batch_normalization_24[0][0]'] \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 56, 56, 12)   10368       ['activation_24[0][0]']          \n","                                                                                                  \n"," dropout_18 (Dropout)           (None, 56, 56, 12)   0           ['conv2d_23[0][0]']              \n","                                                                                                  \n"," concatenate_18 (Concatenate)   (None, 56, 56, 108)  0           ['concatenate_17[0][0]',         \n","                                                                  'dropout_18[0][0]']             \n","                                                                                                  \n"," batch_normalization_25 (BatchN  (None, 56, 56, 108)  432        ['concatenate_18[0][0]']         \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_25 (Activation)     (None, 56, 56, 108)  0           ['batch_normalization_25[0][0]'] \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 56, 56, 12)   11664       ['activation_25[0][0]']          \n","                                                                                                  \n"," dropout_19 (Dropout)           (None, 56, 56, 12)   0           ['conv2d_24[0][0]']              \n","                                                                                                  \n"," concatenate_19 (Concatenate)   (None, 56, 56, 120)  0           ['concatenate_18[0][0]',         \n","                                                                  'dropout_19[0][0]']             \n","                                                                                                  \n"," batch_normalization_26 (BatchN  (None, 56, 56, 120)  480        ['concatenate_19[0][0]']         \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_26 (Activation)     (None, 56, 56, 120)  0           ['batch_normalization_26[0][0]'] \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 56, 56, 120)  14400       ['activation_26[0][0]']          \n","                                                                                                  \n"," average_pooling2d_3 (AveragePo  (None, 28, 28, 120)  0          ['conv2d_25[0][0]']              \n"," oling2D)                                                                                         \n","                                                                                                  \n"," batch_normalization_27 (BatchN  (None, 28, 28, 120)  480        ['average_pooling2d_3[0][0]']    \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_27 (Activation)     (None, 28, 28, 120)  0           ['batch_normalization_27[0][0]'] \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 28, 28, 12)   12960       ['activation_27[0][0]']          \n","                                                                                                  \n"," dropout_20 (Dropout)           (None, 28, 28, 12)   0           ['conv2d_26[0][0]']              \n","                                                                                                  \n"," concatenate_20 (Concatenate)   (None, 28, 28, 132)  0           ['average_pooling2d_3[0][0]',    \n","                                                                  'dropout_20[0][0]']             \n","                                                                                                  \n"," batch_normalization_28 (BatchN  (None, 28, 28, 132)  528        ['concatenate_20[0][0]']         \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_28 (Activation)     (None, 28, 28, 132)  0           ['batch_normalization_28[0][0]'] \n","                                                                                                  \n"," conv2d_27 (Conv2D)             (None, 28, 28, 12)   14256       ['activation_28[0][0]']          \n","                                                                                                  \n"," dropout_21 (Dropout)           (None, 28, 28, 12)   0           ['conv2d_27[0][0]']              \n","                                                                                                  \n"," concatenate_21 (Concatenate)   (None, 28, 28, 144)  0           ['concatenate_20[0][0]',         \n","                                                                  'dropout_21[0][0]']             \n","                                                                                                  \n"," batch_normalization_29 (BatchN  (None, 28, 28, 144)  576        ['concatenate_21[0][0]']         \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_29 (Activation)     (None, 28, 28, 144)  0           ['batch_normalization_29[0][0]'] \n","                                                                                                  \n"," conv2d_28 (Conv2D)             (None, 28, 28, 12)   15552       ['activation_29[0][0]']          \n","                                                                                                  \n"," dropout_22 (Dropout)           (None, 28, 28, 12)   0           ['conv2d_28[0][0]']              \n","                                                                                                  \n"," concatenate_22 (Concatenate)   (None, 28, 28, 156)  0           ['concatenate_21[0][0]',         \n","                                                                  'dropout_22[0][0]']             \n","                                                                                                  \n"," batch_normalization_30 (BatchN  (None, 28, 28, 156)  624        ['concatenate_22[0][0]']         \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_30 (Activation)     (None, 28, 28, 156)  0           ['batch_normalization_30[0][0]'] \n","                                                                                                  \n"," conv2d_29 (Conv2D)             (None, 28, 28, 12)   16848       ['activation_30[0][0]']          \n","                                                                                                  \n"," dropout_23 (Dropout)           (None, 28, 28, 12)   0           ['conv2d_29[0][0]']              \n","                                                                                                  \n"," concatenate_23 (Concatenate)   (None, 28, 28, 168)  0           ['concatenate_22[0][0]',         \n","                                                                  'dropout_23[0][0]']             \n","                                                                                                  \n"," batch_normalization_31 (BatchN  (None, 28, 28, 168)  672        ['concatenate_23[0][0]']         \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_31 (Activation)     (None, 28, 28, 168)  0           ['batch_normalization_31[0][0]'] \n","                                                                                                  \n"," global_average_pooling2d_1 (Gl  (None, 168)         0           ['activation_31[0][0]']          \n"," obalAveragePooling2D)                                                                            \n","                                                                                                  \n"," dense_1 (Dense)                (None, 16)           2704        ['global_average_pooling2d_1[0][0\n","                                                                 ]']                              \n","                                                                                                  \n","==================================================================================================\n","Total params: 145,336\n","Trainable params: 142,456\n","Non-trainable params: 2,880\n","__________________________________________________________________________________________________\n"]}],"source":["# we will build the model using the Keras API\n","\n","# def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):\n","#   print(\"Building the model with:\", MODEL_URL)\n","\n","#   # Setup the model layers\n","#   model = tf.keras.Sequential([\n","#     hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n","#     tf.keras.layers.Dense(units=OUTPUT_SHAPE, \n","#                           activation=\"softmax\") # Layer 2 (output layer). Softmax will predict the probabilities for each class for each image\n","#   ])\n","\n","#   # Compile the model\n","#   model.compile(\n","#       loss=tf.keras.losses.CategoricalCrossentropy(), # Our model wants to reduce this (how wrong its guesses are)\n","#       optimizer=tf.keras.optimizers.Adam(), # An optimizer helping our model how to improve its guesses\n","#       metrics=[\"accuracy\"] # We'd like this to go up\n","#   )\n","\n","#   # Build the model\n","#   model.build(INPUT_SHAPE) # Let the model know what kind of inputs it'll be getting\n","  \n","#   return model\n","\n","dense_block_size = 3\n","layers_in_block = 4\n","\n","growth_rate = 12\n","classes = 16\n","model = dense_net(growth_rate * 2, growth_rate, classes, dense_block_size, layers_in_block)\n","model.summary()\n"]},{"cell_type":"code","source":["# Compile the model\n","model.compile(\n","    loss=tf.keras.losses.CategoricalCrossentropy(), # Our model wants to reduce this (how wrong its guesses are)\n","    optimizer=tf.keras.optimizers.Adam(), # An optimizer helping our model how to improve its guesses\n","    metrics=[\"accuracy\"] # We'd like this to go up\n",")\n","full_model2 = model"],"metadata":{"id":"RTi4EpCkywUH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TQ5fZFDQ4gw5"},"source":["## Creating the Model 2 for Full data Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D0Mvji6nKscJ"},"outputs":[],"source":["# # Instantiate a new model for training on the full dataset\n","# full_model2 = create_model()\n","# full_model2.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WNLYMgjtuhqA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668240658005,"user_tz":-330,"elapsed":16,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"79a58ab4-8d20-4d87-ceb6-6dc7fcb6383a"},"outputs":[{"output_type":"stream","name":"stdout","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"]}],"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","import datetime\n","\n","# Create a function to build a TensorBoard callback\n","def create_tensorboard_callback():\n","  # Create a log directory for storing TensorBoard logs\n","  logdir = os.path.join(\"logs\",\n","                        # Make it so the logs get tracked whenever we run an experiment\n","                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","  return tf.keras.callbacks.TensorBoard(logdir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fnhQKzX8KuM8"},"outputs":[],"source":["# Create full model callbacks\n","\n","# TensorBoard callback\n","full_model_tensorboard = create_tensorboard_callback()\n","\n","# Early stopping callback\n","# Note: No validation set when training on all the data, so we monitor only training accuracy\n","full_model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",\n","                                                             patience=4)\n","\n","logger= tf.keras.callbacks.CSVLogger(\"dense-net-logger.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5HVZ9qF5MrvZ"},"outputs":[],"source":["def save_model(model, suffix=None):\n","  \"\"\"\n","  Saves a given model in a models directory and appends a suffix (str)\n","  for clarity and reuse.\n","  \"\"\"\n","  # Create model directory with current time\n","  modeldir = os.path.join(\"models_archit\",\n","                          datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n","  model_path = modeldir + \"-\" + suffix + \".h5\" # save format of model\n","  print(f\"Saving model to: {model_path}...\")\n","  model.save(model_path)\n","  return model_path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y8u-65LpMt0w"},"outputs":[],"source":["def load_model(model_path):\n","  \"\"\"\n","  Loads a saved model from a specified path.\n","  \"\"\"\n","  print(f\"Loading saved model from: {model_path}\")\n","  model = tf.keras.models.load_model(model_path,\n","                                     custom_objects={\"KerasLayer\":hub.KerasLayer})\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"02CIR-wyQ8sr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668246075878,"user_tz":-330,"elapsed":5258592,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"72906763-fc34-4071-e27f-c35447690f5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","500/500 [==============================] - 4661s 9s/step - loss: 1.9510 - accuracy: 0.3977\n","Epoch 2/5\n","500/500 [==============================] - 127s 254ms/step - loss: 1.6479 - accuracy: 0.4980\n","Epoch 3/5\n","500/500 [==============================] - 126s 251ms/step - loss: 1.5258 - accuracy: 0.5320\n","Epoch 4/5\n","500/500 [==============================] - 130s 260ms/step - loss: 1.4473 - accuracy: 0.5602\n","Epoch 5/5\n","500/500 [==============================] - 130s 260ms/step - loss: 1.3894 - accuracy: 0.5771\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8fa7667d10>"]},"metadata":{},"execution_count":53}],"source":["# Fit the full model to the full training data\n","full_model2.fit(x=full_data,\n","               epochs=5,\n","               callbacks=[full_model_tensorboard, \n","                          full_model_early_stopping, logger])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HI4SVAQaMwXV","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1668246089734,"user_tz":-330,"elapsed":901,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"98d54f91-e96c-41eb-afa6-ed005ca5f347"},"outputs":[{"output_type":"stream","name":"stdout","text":["Saving model to: models_archit/20221112-09411668246088-dense-net.h5...\n"]},{"output_type":"execute_result","data":{"text/plain":["'models_archit/20221112-09411668246088-dense-net.h5'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":54}],"source":["# Save our model trained on 4000 images from the Training Dataset\n","# save_model(full_model2, suffix=\"res-net\")\n","save_model(full_model2, suffix=\"dense-net\")"]},{"cell_type":"code","source":["# check train and test data size"],"metadata":{"id":"sCf_IBZ1BIlc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CNmB7eYIMywr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668246110305,"user_tz":-330,"elapsed":2563,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"3d5f2fc8-ceee-4c12-def3-6d7c9ae132ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading saved model from: models_archit/20221112-09411668246088-dense-net.h5\n"]}],"source":["# Load our model trained on 1000 images\n","loaded_model = load_model('models_archit/20221112-09411668246088-dense-net.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VUgnLfpV9Wme","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668246111561,"user_tz":-330,"elapsed":15,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"dbea399c-0005-4af6-f65a-58cb69390354"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating validation data batches...\n"]}],"source":["X_val = X[:500]\n","y_val = y[:500]\n","val_data = create_data_batches(X_val, y_val, valid_data=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DgffU6nG94Mm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668246117461,"user_tz":-330,"elapsed":5912,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"c33b5c45-c586-4964-ad45-ad80a68b6e02"},"outputs":[{"output_type":"stream","name":"stdout","text":["16/16 [==============================] - 4s 246ms/step - loss: 4.3942 - accuracy: 0.2400\n"]},{"output_type":"execute_result","data":{"text/plain":["[4.3941779136657715, 0.23999999463558197]"]},"metadata":{},"execution_count":57}],"source":["# Evaluate the loaded model\n","loaded_model.evaluate(val_data)"]},{"cell_type":"code","source":["predictions = loaded_model.predict(val_data, verbose=1) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tslYVCvFZTfu","executionInfo":{"status":"ok","timestamp":1668246125213,"user_tz":-330,"elapsed":3965,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"357781b7-6ca2-4d09-dda0-58de5daae4d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["16/16 [==============================] - 4s 221ms/step\n"]}]},{"cell_type":"code","source":["predictions.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m81HAQAMZuVF","executionInfo":{"status":"ok","timestamp":1668246126614,"user_tz":-330,"elapsed":5,"user":{"displayName":"totally reliable","userId":"15953242274047744585"}},"outputId":"677b141e-b13c-4a03-89c7-a979eaf7758d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(500, 16)"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["predictions=pd.DataFrame(predictions)\n","predictions.to_csv('drive/MyDrive/Datathon/approx_predicted_label_dense-net.csv')"],"metadata":{"id":"wYdDjvY2aFNE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfQwWQmi-9ee"},"outputs":[],"source":["# # Turn prediction probabilities into their labels (Document Types)\n","# def get_pred_label(prediction_probabilities):\n","#   \"\"\"\n","#   Turns an array of prediction probabilities into a label.\n","#   \"\"\"\n","#   return unique_labels[np.argmax(prediction_probabilities)]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jh7rKKQFGefG"},"outputs":[],"source":["# model_path = \"models_archit/20221112-00031668211416-efficient-net.h5\" \n","# data_path = \"validation/validation\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7U88mvoxGc6q"},"outputs":[],"source":["# # Function to test the validation data stored in 'data_path' with the model stored in 'model_path'\n","# # here, model_path = \"drive/MyDrive/Datathon/models/20221007-08281665131319-full-trained-adam.h5\" \n","# #       data_path = \"drive/MyDrive/Datathon/validation/validation\"\n","\n","# def test(model_path, data_path):\n","#   # Load the fully trained model\n","#   loaded_full_model = load_model(model_path)\n","\n","#   # Load validation image filenames\n","#   val_path = data_path\n","#   val_filenames = [val_path + fname for fname in os.listdir(val_path)]\n","\n","#   # Getting the list of validation set IDs\n","#   val_id = [id for id in os.listdir(val_path)]\n","#   val_ids = []\n","#   for item in val_id:\n","#     val_ids.append(int(item.split(\".\")[0]))\n","  \n","#   # Create validation data batch so as to turn it into tensors and then fit it in our model\n","#   val_data = create_data_batches(val_filenames, test_data=True) \n","\n","#   # Make predictions on the validation data \n","#   predictions = loaded_full_model.predict(val_data, verbose=1) \n","  \n","#   # Getting the predicted labels in array val_pred_labels[]\n","#   val_pred_labels = []\n","#   for i in range(len(val_ids)):\n","#     val_pred_labels.append(get_pred_label(predictions[i]))\n","  \n","#   # Fitting the data into Pandas dataframe\n","#   data = []\n","#   for i in range(len(val_ids)):\n","#     data.append((val_ids[i], val_pred_labels[i]))\n","#   df = pd.DataFrame(data, columns=['id','label'])\n","\n","#   # Saving the predicted labels on validation set images in CSV\n","#   # Saving the predictions to predicted_label.csv file and saving it inside the datathon folder in GDrive\n","#   # df.to_csv(r'drive/MyDrive/Datathon/predicted_label2.csv', index=False)\n","\n","#   df.to_csv(r'predicted_label_mobile-net.csv', index=False)  \n","#   # df.to_csv(r'predicted_label_efficient-net.csv', index=False)  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mhmWn7z10bh3"},"outputs":[],"source":["# test(model_path, data_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W48rem9SGj9L"},"outputs":[],"source":["# data= pd.read_csv('drive/MyDrive/Datathon/predicted_label.csv')\n","# data"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}